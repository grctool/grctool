# HELIX Cross-Phase Dependency Traceability System\n\n## Overview\n\nThis document establishes a comprehensive traceability system for tracking dependencies, relationships, and artifacts across all phases of the HELIX workflow. This system ensures complete visibility into how requirements flow through design, testing, implementation, deployment, and continuous improvement, providing essential audit trails for compliance and quality assurance.\n\n## Traceability Architecture\n\n### Core Traceability Components\n\n```yaml\ntraceability_architecture:\n  artifact_registry:\n    description: \"Central repository of all HELIX artifacts\"\n    storage: \"JSON-based with metadata indexing\"\n    versioning: \"Git-based with artifact-specific versioning\"\n    \n  dependency_matrix:\n    description: \"Bidirectional dependency relationships\"\n    types: [\"requires\", \"influences\", \"validates\", \"implements\", \"tests\"]\n    granularity: [\"artifact\", \"section\", \"requirement\", \"control\"]\n    \n  change_impact_analysis:\n    description: \"Automated impact assessment for changes\"\n    triggers: [\"artifact_update\", \"requirement_change\", \"design_modification\"]\n    scope: [\"downstream_artifacts\", \"test_coverage\", \"implementation_status\"]\n    \n  audit_trail:\n    description: \"Complete history of all traceability relationships\"\n    retention: \"Permanent for compliance requirements\"\n    format: \"Structured JSON with cryptographic integrity\"\n```\n\n### Artifact Identification System\n\n#### Unique Artifact Identifiers\n```yaml\nartifact_id_schema:\n  format: \"{phase_code}-{category_code}-{artifact_number}-{version}\"\n  \n  phase_codes:\n    frame: \"F\"\n    design: \"D\"\n    test: \"T\"\n    build: \"B\"\n    deploy: \"P\"  # Production\n    iterate: \"I\"\n    \n  category_codes:\n    requirements: \"REQ\"\n    user_stories: \"USR\"\n    architecture: \"ARC\"\n    security_design: \"SEC\"\n    test_cases: \"TST\"\n    test_procedures: \"TPR\"\n    source_code: \"SRC\"\n    build_artifacts: \"BLD\"\n    deployment_config: \"CFG\"\n    deployment_procedures: \"DEP\"\n    metrics: \"MET\"\n    feedback: \"FBK\"\n    \n  examples:\n    - \"F-REQ-001-v1.2\"  # Frame phase requirement document v1.2\n    - \"D-ARC-003-v2.0\"  # Design phase architecture document v2.0\n    - \"T-TST-045-v1.0\"  # Test phase test case v1.0\n    - \"B-SRC-012-v3.1\"  # Build phase source code module v3.1\n```\n\n### Dependency Relationship Types\n\n#### Primary Relationship Categories\n```yaml\nrelationship_types:\n  requires:\n    description: \"Artifact A cannot be completed without artifact B\"\n    direction: \"A â†’ B (A requires B)\"\n    examples:\n      - \"D-ARC-001 requires F-REQ-001\"\n      - \"T-TST-001 requires D-ARC-001\"\n      \n  implements:\n    description: \"Artifact A implements the specification in artifact B\"\n    direction: \"A â†’ B (A implements B)\"\n    examples:\n      - \"B-SRC-001 implements D-ARC-001\"\n      - \"P-CFG-001 implements D-SEC-001\"\n      \n  validates:\n    description: \"Artifact A provides validation for artifact B\"\n    direction: \"A â†’ B (A validates B)\"\n    examples:\n      - \"T-TST-001 validates B-SRC-001\"\n      - \"I-MET-001 validates P-DEP-001\"\n      \n  influences:\n    description: \"Artifact A impacts or constrains artifact B\"\n    direction: \"A â†’ B (A influences B)\"\n    examples:\n      - \"F-REQ-001 influences D-ARC-001\"\n      - \"I-FBK-001 influences F-REQ-002\"\n      \n  traces_to:\n    description: \"Artifact A can be traced back to artifact B\"\n    direction: \"A â†’ B (A traces to B)\"\n    examples:\n      - \"B-SRC-001 traces_to F-USR-001\"\n      - \"P-DEP-001 traces_to F-REQ-001\"\n```\n\n## Traceability Implementation\n\n### Artifact Metadata Schema\n\n```json\n{\n  \"artifact_id\": \"F-REQ-001-v1.2\",\n  \"metadata\": {\n    \"title\": \"SOC2 Evidence Collection Requirements\",\n    \"phase\": \"frame\",\n    \"category\": \"requirements\",\n    \"version\": \"1.2\",\n    \"status\": \"approved\",\n    \"created_date\": \"2025-01-15T10:30:00Z\",\n    \"modified_date\": \"2025-01-20T14:45:00Z\",\n    \"author\": \"product-manager\",\n    \"reviewers\": [\"compliance-expert\", \"tech-lead\"],\n    \"approval_status\": \"approved\",\n    \"approval_date\": \"2025-01-20T16:00:00Z\"\n  },\n  \"content\": {\n    \"file_path\": \"docs/helix/01-frame/01-product-requirements.md\",\n    \"sections\": [\n      {\n        \"section_id\": \"F-REQ-001-SEC-01\",\n        \"title\": \"Evidence Automation Requirements\",\n        \"content_hash\": \"sha256:a1b2c3d4...\",\n        \"line_range\": [25, 67]\n      },\n      {\n        \"section_id\": \"F-REQ-001-SEC-02\",\n        \"title\": \"Compliance Framework Support\",\n        \"content_hash\": \"sha256:e5f6g7h8...\",\n        \"line_range\": [68, 145]\n      }\n    ]\n  },\n  \"relationships\": {\n    \"requires\": [],\n    \"influences\": [\"D-ARC-001-v1.0\", \"D-SEC-001-v1.0\"],\n    \"implemented_by\": [\"B-SRC-001-v2.1\", \"B-SRC-005-v1.8\"],\n    \"validated_by\": [\"T-TST-001-v1.0\", \"T-TST-003-v1.0\"],\n    \"traces_from\": [\"F-USR-001-v1.0\", \"F-USR-003-v1.0\"]\n  },\n  \"compliance_mapping\": {\n    \"soc2_controls\": [\"CC6.1\", \"CC6.7\", \"CC8.1\"],\n    \"iso27001_controls\": [\"A.9.1.1\", \"A.12.1.1\"],\n    \"evidence_tasks\": [\"ET-0001\", \"ET-0015\", \"ET-0029\"]\n  },\n  \"change_history\": [\n    {\n      \"version\": \"1.2\",\n      \"date\": \"2025-01-20T14:45:00Z\",\n      \"author\": \"product-manager\",\n      \"change_type\": \"requirement_update\",\n      \"description\": \"Added ISO27001 compliance requirements\",\n      \"impacted_artifacts\": [\"D-ARC-001\", \"T-TST-001\"]\n    }\n  ]\n}\n```\n\n### Traceability Matrix Generator\n\n```python\n#!/usr/bin/env python3\n# scripts/generate_traceability_matrix.py\n\nimport json\nimport os\nimport hashlib\nfrom pathlib import Path\nfrom typing import Dict, List, Set, Optional\nfrom dataclasses import dataclass\nfrom datetime import datetime\n\n@dataclass\nclass ArtifactReference:\n    artifact_id: str\n    section_id: Optional[str] = None\n    line_range: Optional[tuple] = None\n    relationship_type: str = \"requires\"\n\n@dataclass\nclass TraceabilityRelationship:\n    source_artifact: str\n    target_artifact: str\n    relationship_type: str\n    confidence: float  # 0.0 to 1.0\n    validation_status: str  # \"validated\", \"assumed\", \"needs_verification\"\n    last_verified: Optional[datetime] = None\n\nclass TraceabilityMatrix:\n    def __init__(self, helix_root: str = \"docs/helix\"):\n        self.helix_root = Path(helix_root)\n        self.artifacts = {}\n        self.relationships = []\n        self.compliance_mappings = {}\n        \n    def discover_artifacts(self) -> Dict[str, Dict]:\n        \"\"\"Discover all HELIX artifacts and extract metadata\"\"\"\n        artifacts = {}\n        \n        # Phase directories mapping\n        phase_dirs = {\n            \"frame\": \"01-frame\",\n            \"design\": \"02-design\", \n            \"test\": \"03-test\",\n            \"build\": \"04-build\",\n            \"deploy\": \"05-deploy\",\n            \"iterate\": \"06-iterate\"\n        }\n        \n        for phase, dir_name in phase_dirs.items():\n            phase_path = self.helix_root / dir_name\n            if not phase_path.exists():\n                continue\n                \n            for md_file in phase_path.glob(\"**/*.md\"):\n                artifact = self._extract_artifact_metadata(md_file, phase)\n                if artifact:\n                    artifacts[artifact[\"artifact_id\"]] = artifact\n                    \n        # Also scan for code artifacts\n        code_artifacts = self._discover_code_artifacts()\n        artifacts.update(code_artifacts)\n        \n        # Scan for test artifacts\n        test_artifacts = self._discover_test_artifacts()\n        artifacts.update(test_artifacts)\n        \n        self.artifacts = artifacts\n        return artifacts\n    \n    def _extract_artifact_metadata(self, file_path: Path, phase: str) -> Optional[Dict]:\n        \"\"\"Extract metadata from markdown file frontmatter\"\"\"\n        try:\n            with open(file_path, 'r', encoding='utf-8') as f:\n                content = f.read()\n                \n            # Extract frontmatter\n            if not content.startswith('---'):\n                return None\n                \n            end_frontmatter = content.find('---', 3)\n            if end_frontmatter == -1:\n                return None\n                \n            frontmatter = content[3:end_frontmatter]\n            body = content[end_frontmatter + 3:]\n            \n            # Parse frontmatter (simplified YAML parsing)\n            metadata = {}\n            for line in frontmatter.strip().split('\\n'):\n                if ':' in line:\n                    key, value = line.split(':', 1)\n                    metadata[key.strip()] = value.strip().strip('\"\\'')\n            \n            # Generate artifact ID\n            artifact_id = self._generate_artifact_id(file_path, phase, metadata)\n            \n            # Extract sections and their relationships\n            sections = self._extract_sections(body)\n            \n            # Extract compliance mappings\n            compliance_mapping = self._extract_compliance_mapping(body)\n            \n            # Extract relationships from content\n            relationships = self._extract_relationships_from_content(body)\n            \n            return {\n                \"artifact_id\": artifact_id,\n                \"metadata\": {\n                    \"title\": metadata.get('title', file_path.stem),\n                    \"phase\": phase,\n                    \"category\": self._determine_category(file_path, metadata),\n                    \"version\": \"1.0\",  # Default version\n                    \"status\": metadata.get('status', 'draft'),\n                    \"created_date\": datetime.now().isoformat(),\n                    \"file_path\": str(file_path.relative_to(Path.cwd())),\n                    \"content_hash\": hashlib.sha256(content.encode()).hexdigest()[:16]\n                },\n                \"content\": {\n                    \"file_path\": str(file_path),\n                    \"sections\": sections,\n                    \"word_count\": len(body.split()),\n                    \"line_count\": len(body.split('\\n'))\n                },\n                \"relationships\": relationships,\n                \"compliance_mapping\": compliance_mapping\n            }\n            \n        except Exception as e:\n            print(f\"Error processing {file_path}: {e}\")\n            return None\n    \n    def _generate_artifact_id(self, file_path: Path, phase: str, metadata: Dict) -> str:\n        \"\"\"Generate unique artifact ID based on file and metadata\"\"\"\n        phase_code = phase[0].upper()  # F, D, T, B, P, I\n        \n        # Determine category code\n        category_codes = {\n            \"requirements\": \"REQ\",\n            \"user-stories\": \"USR\", \n            \"architecture\": \"ARC\",\n            \"security\": \"SEC\",\n            \"testing\": \"TST\",\n            \"development\": \"DEV\",\n            \"deployment\": \"DEP\",\n            \"roadmap\": \"RDM\",\n            \"feedback\": \"FBK\"\n        }\n        \n        category = self._determine_category(file_path, metadata)\n        category_code = category_codes.get(category, \"GEN\")\n        \n        # Generate sequence number based on file name\n        sequence = abs(hash(str(file_path))) % 1000\n        \n        return f\"{phase_code}-{category_code}-{sequence:03d}-v1.0\"\n    \n    def _determine_category(self, file_path: Path, metadata: Dict) -> str:\n        \"\"\"Determine artifact category from file path and metadata\"\"\"\n        file_name = file_path.stem.lower()\n        \n        if 'requirement' in file_name:\n            return 'requirements'\n        elif 'user' in file_name and 'stor' in file_name:\n            return 'user-stories'\n        elif 'architecture' in file_name:\n            return 'architecture'\n        elif 'security' in file_name:\n            return 'security'\n        elif 'test' in file_name:\n            return 'testing'\n        elif 'development' in file_name or 'practice' in file_name:\n            return 'development'\n        elif 'deployment' in file_name or 'operation' in file_name:\n            return 'deployment'\n        elif 'roadmap' in file_name:\n            return 'roadmap'\n        elif 'feedback' in file_name:\n            return 'feedback'\n        else:\n            return 'general'\n    \n    def _extract_sections(self, content: str) -> List[Dict]:\n        \"\"\"Extract sections from markdown content\"\"\"\n        sections = []\n        lines = content.split('\\n')\n        current_section = None\n        section_start = 0\n        \n        for i, line in enumerate(lines):\n            if line.startswith('#'):\n                # Save previous section\n                if current_section:\n                    current_section['line_range'] = (section_start, i - 1)\n                    current_section['content_hash'] = hashlib.sha256(\n                        '\\n'.join(lines[section_start:i]).encode()\n                    ).hexdigest()[:16]\n                    sections.append(current_section)\n                \n                # Start new section\n                level = len(line) - len(line.lstrip('#'))\n                title = line.lstrip('#').strip()\n                section_id = f\"SEC-{len(sections)+1:03d}\"\n                \n                current_section = {\n                    'section_id': section_id,\n                    'title': title,\n                    'level': level,\n                    'line_start': i\n                }\n                section_start = i\n        \n        # Handle last section\n        if current_section:\n            current_section['line_range'] = (section_start, len(lines) - 1)\n            current_section['content_hash'] = hashlib.sha256(\n                '\\n'.join(lines[section_start:]).encode()\n            ).hexdigest()[:16]\n            sections.append(current_section)\n        \n        return sections\n    \n    def _extract_compliance_mapping(self, content: str) -> Dict:\n        \"\"\"Extract compliance control mappings from content\"\"\"\n        import re\n        \n        mappings = {\n            'soc2_controls': [],\n            'iso27001_controls': [],\n            'evidence_tasks': []\n        }\n        \n        # Extract SOC2 controls (CC#.#)\n        soc2_pattern = r'\\bCC\\d+\\.\\d+\\b'\n        mappings['soc2_controls'] = list(set(re.findall(soc2_pattern, content)))\n        \n        # Extract ISO27001 controls (A.#.#.#)\n        iso_pattern = r'\\bA\\.\\d+\\.\\d+\\.\\d+\\b'\n        mappings['iso27001_controls'] = list(set(re.findall(iso_pattern, content)))\n        \n        # Extract evidence tasks (ET-####)\n        et_pattern = r'\\bET-\\d{4}\\b'\n        mappings['evidence_tasks'] = list(set(re.findall(et_pattern, content)))\n        \n        return mappings\n    \n    def _extract_relationships_from_content(self, content: str) -> Dict[str, List[str]]:\n        \"\"\"Extract artifact relationships from content references\"\"\"\n        import re\n        \n        relationships = {\n            'requires': [],\n            'influences': [],\n            'implements': [],\n            'validates': [],\n            'traces_to': []\n        }\n        \n        # Look for artifact references in various formats\n        artifact_patterns = [\n            r'\\[\\[([^\\]]+)\\]\\]',  # [[artifact-name]]\n            r'see ([A-Z]-[A-Z]{3}-\\d{3}-v\\d+\\.\\d+)',  # see F-REQ-001-v1.0\n            r'based on ([A-Z]-[A-Z]{3}-\\d{3}-v\\d+\\.\\d+)',  # based on D-ARC-001-v1.0\n        ]\n        \n        for pattern in artifact_patterns:\n            matches = re.findall(pattern, content, re.IGNORECASE)\n            # This is a simplified implementation\n            # In practice, you'd need more sophisticated parsing\n            # to determine relationship types from context\n            relationships['requires'].extend(matches)\n        \n        return relationships\n    \n    def _discover_code_artifacts(self) -> Dict[str, Dict]:\n        \"\"\"Discover code artifacts from source tree\"\"\"\n        artifacts = {}\n        \n        # Scan Go source files\n        for go_file in Path('internal').glob('**/*.go'):\n            if go_file.name.endswith('_test.go'):\n                continue  # Skip test files here\n                \n            artifact_id = f\"B-SRC-{abs(hash(str(go_file))) % 1000:03d}-v1.0\"\n            \n            with open(go_file, 'r', encoding='utf-8') as f:\n                content = f.read()\n            \n            artifacts[artifact_id] = {\n                \"artifact_id\": artifact_id,\n                \"metadata\": {\n                    \"title\": f\"Source: {go_file.stem}\",\n                    \"phase\": \"build\",\n                    \"category\": \"source_code\",\n                    \"version\": \"1.0\",\n                    \"file_path\": str(go_file),\n                    \"content_hash\": hashlib.sha256(content.encode()).hexdigest()[:16]\n                },\n                \"content\": {\n                    \"file_path\": str(go_file),\n                    \"language\": \"go\",\n                    \"line_count\": len(content.split('\\n')),\n                    \"functions\": self._extract_go_functions(content)\n                },\n                \"relationships\": self._extract_code_relationships(content),\n                \"compliance_mapping\": {}\n            }\n        \n        return artifacts\n    \n    def _discover_test_artifacts(self) -> Dict[str, Dict]:\n        \"\"\"Discover test artifacts\"\"\"\n        artifacts = {}\n        \n        # Scan test files\n        for test_file in Path('.').glob('**/*_test.go'):\n            artifact_id = f\"T-TST-{abs(hash(str(test_file))) % 1000:03d}-v1.0\"\n            \n            with open(test_file, 'r', encoding='utf-8') as f:\n                content = f.read()\n            \n            artifacts[artifact_id] = {\n                \"artifact_id\": artifact_id,\n                \"metadata\": {\n                    \"title\": f\"Test: {test_file.stem}\",\n                    \"phase\": \"test\",\n                    \"category\": \"test_code\",\n                    \"version\": \"1.0\",\n                    \"file_path\": str(test_file),\n                    \"content_hash\": hashlib.sha256(content.encode()).hexdigest()[:16]\n                },\n                \"content\": {\n                    \"file_path\": str(test_file),\n                    \"language\": \"go\",\n                    \"test_functions\": self._extract_test_functions(content)\n                },\n                \"relationships\": self._extract_test_relationships(content),\n                \"compliance_mapping\": {}\n            }\n        \n        return artifacts\n    \n    def analyze_dependencies(self) -> List[TraceabilityRelationship]:\n        \"\"\"Analyze and validate all dependency relationships\"\"\"\n        relationships = []\n        \n        for artifact_id, artifact in self.artifacts.items():\n            for rel_type, targets in artifact.get('relationships', {}).items():\n                for target in targets:\n                    if target in self.artifacts:\n                        relationship = TraceabilityRelationship(\n                            source_artifact=artifact_id,\n                            target_artifact=target,\n                            relationship_type=rel_type,\n                            confidence=0.8,  # Default confidence\n                            validation_status=\"needs_verification\"\n                        )\n                        relationships.append(relationship)\n        \n        # Add inferred relationships based on naming patterns\n        inferred = self._infer_relationships()\n        relationships.extend(inferred)\n        \n        self.relationships = relationships\n        return relationships\n    \n    def _infer_relationships(self) -> List[TraceabilityRelationship]:\n        \"\"\"Infer relationships based on naming patterns and content analysis\"\"\"\n        relationships = []\n        \n        # Infer Frame â†’ Design relationships\n        frame_artifacts = [aid for aid, art in self.artifacts.items() if art['metadata']['phase'] == 'frame']\n        design_artifacts = [aid for aid, art in self.artifacts.items() if art['metadata']['phase'] == 'design']\n        \n        for frame_id in frame_artifacts:\n            for design_id in design_artifacts:\n                # Check if design artifact references frame artifact\n                design_artifact = self.artifacts[design_id]\n                if self._contains_reference(design_artifact, frame_id):\n                    relationships.append(TraceabilityRelationship(\n                        source_artifact=design_id,\n                        target_artifact=frame_id,\n                        relationship_type=\"requires\",\n                        confidence=0.7,\n                        validation_status=\"inferred\"\n                    ))\n        \n        # Similar logic for other phase transitions...\n        \n        return relationships\n    \n    def _contains_reference(self, artifact: Dict, target_id: str) -> bool:\n        \"\"\"Check if artifact contains reference to target\"\"\"\n        # This is a simplified check - in practice you'd want more sophisticated analysis\n        content_str = str(artifact.get('content', ''))\n        return target_id in content_str or any(\n            target_id in str(rel_list) for rel_list in artifact.get('relationships', {}).values()\n        )\n    \n    def generate_traceability_matrix(self) -> Dict:\n        \"\"\"Generate comprehensive traceability matrix\"\"\"\n        matrix = {\n            \"metadata\": {\n                \"generated_at\": datetime.now().isoformat(),\n                \"total_artifacts\": len(self.artifacts),\n                \"total_relationships\": len(self.relationships),\n                \"coverage_analysis\": self._analyze_coverage()\n            },\n            \"artifacts\": self.artifacts,\n            \"relationships\": [\n                {\n                    \"source\": rel.source_artifact,\n                    \"target\": rel.target_artifact,\n                    \"type\": rel.relationship_type,\n                    \"confidence\": rel.confidence,\n                    \"validation_status\": rel.validation_status\n                }\n                for rel in self.relationships\n            ],\n            \"compliance_coverage\": self._analyze_compliance_coverage(),\n            \"gaps\": self._identify_gaps(),\n            \"recommendations\": self._generate_recommendations()\n        }\n        \n        return matrix\n    \n    def _analyze_coverage(self) -> Dict:\n        \"\"\"Analyze traceability coverage across phases\"\"\"\n        phase_counts = {}\n        for artifact in self.artifacts.values():\n            phase = artifact['metadata']['phase']\n            phase_counts[phase] = phase_counts.get(phase, 0) + 1\n        \n        # Calculate relationship density\n        total_possible = len(self.artifacts) * (len(self.artifacts) - 1)\n        actual_relationships = len(self.relationships)\n        density = actual_relationships / total_possible if total_possible > 0 else 0\n        \n        return {\n            \"artifacts_by_phase\": phase_counts,\n            \"relationship_density\": density,\n            \"coverage_percentage\": self._calculate_coverage_percentage()\n        }\n    \n    def _calculate_coverage_percentage(self) -> float:\n        \"\"\"Calculate percentage of artifacts with established relationships\"\"\"\n        connected_artifacts = set()\n        for rel in self.relationships:\n            connected_artifacts.add(rel.source_artifact)\n            connected_artifacts.add(rel.target_artifact)\n        \n        return len(connected_artifacts) / len(self.artifacts) * 100 if self.artifacts else 0\n    \n    def _analyze_compliance_coverage(self) -> Dict:\n        \"\"\"Analyze compliance control coverage across artifacts\"\"\"\n        all_soc2_controls = set()\n        all_iso_controls = set()\n        all_evidence_tasks = set()\n        \n        for artifact in self.artifacts.values():\n            mapping = artifact.get('compliance_mapping', {})\n            all_soc2_controls.update(mapping.get('soc2_controls', []))\n            all_iso_controls.update(mapping.get('iso27001_controls', []))\n            all_evidence_tasks.update(mapping.get('evidence_tasks', []))\n        \n        return {\n            \"soc2_controls_covered\": len(all_soc2_controls),\n            \"iso27001_controls_covered\": len(all_iso_controls),\n            \"evidence_tasks_covered\": len(all_evidence_tasks),\n            \"controls_by_artifact\": self._map_controls_to_artifacts()\n        }\n    \n    def _identify_gaps(self) -> List[Dict]:\n        \"\"\"Identify gaps in traceability\"\"\"\n        gaps = []\n        \n        # Check for orphaned artifacts\n        connected_artifacts = set()\n        for rel in self.relationships:\n            connected_artifacts.add(rel.source_artifact)\n            connected_artifacts.add(rel.target_artifact)\n        \n        orphaned = set(self.artifacts.keys()) - connected_artifacts\n        for artifact_id in orphaned:\n            artifact = self.artifacts[artifact_id]\n            gaps.append({\n                \"type\": \"orphaned_artifact\",\n                \"artifact_id\": artifact_id,\n                \"phase\": artifact['metadata']['phase'],\n                \"description\": f\"Artifact {artifact_id} has no traceability relationships\",\n                \"severity\": \"medium\"\n            })\n        \n        # Check for missing forward traceability\n        phase_order = ['frame', 'design', 'test', 'build', 'deploy', 'iterate']\n        for i, phase in enumerate(phase_order[:-1]):\n            next_phase = phase_order[i + 1]\n            \n            current_artifacts = [aid for aid, art in self.artifacts.items() if art['metadata']['phase'] == phase]\n            next_artifacts = [aid for aid, art in self.artifacts.items() if art['metadata']['phase'] == next_phase]\n            \n            for current_id in current_artifacts:\n                has_forward_trace = any(\n                    rel.source_artifact == current_id and \n                    self.artifacts[rel.target_artifact]['metadata']['phase'] == next_phase\n                    for rel in self.relationships\n                )\n                \n                if not has_forward_trace and next_artifacts:\n                    gaps.append({\n                        \"type\": \"missing_forward_traceability\",\n                        \"artifact_id\": current_id,\n                        \"from_phase\": phase,\n                        \"to_phase\": next_phase,\n                        \"description\": f\"No forward traceability from {phase} to {next_phase}\",\n                        \"severity\": \"high\"\n                    })\n        \n        return gaps\n    \n    def _generate_recommendations(self) -> List[str]:\n        \"\"\"Generate recommendations for improving traceability\"\"\"\n        recommendations = []\n        \n        coverage = self._calculate_coverage_percentage()\n        if coverage < 80:\n            recommendations.append(\n                f\"Improve traceability coverage (currently {coverage:.1f}%, target 80%+)\"\n            )\n        \n        gaps = self._identify_gaps()\n        orphaned_count = len([g for g in gaps if g['type'] == 'orphaned_artifact'])\n        if orphaned_count > 0:\n            recommendations.append(\n                f\"Establish relationships for {orphaned_count} orphaned artifacts\"\n            )\n        \n        missing_forward = len([g for g in gaps if g['type'] == 'missing_forward_traceability'])\n        if missing_forward > 0:\n            recommendations.append(\n                f\"Add forward traceability for {missing_forward} phase transitions\"\n            )\n        \n        # Check for validation status\n        unverified = len([r for r in self.relationships if r.validation_status == 'needs_verification'])\n        if unverified > 0:\n            recommendations.append(\n                f\"Verify {unverified} unvalidated traceability relationships\"\n            )\n        \n        return recommendations\n\n# Additional helper methods...\n    def _extract_go_functions(self, content: str) -> List[str]:\n        \"\"\"Extract function names from Go source code\"\"\"\n        import re\n        pattern = r'func\\s+(\\w+)\\s*\\('\n        return re.findall(pattern, content)\n    \n    def _extract_test_functions(self, content: str) -> List[str]:\n        \"\"\"Extract test function names from Go test files\"\"\"\n        import re\n        pattern = r'func\\s+(Test\\w+)\\s*\\('\n        return re.findall(pattern, content)\n    \n    def _extract_code_relationships(self, content: str) -> Dict[str, List[str]]:\n        \"\"\"Extract relationships from code (imports, function calls, etc.)\"\"\"\n        relationships = {\n            'imports': [],\n            'calls': [],\n            'implements': []\n        }\n        \n        # Extract import statements\n        import re\n        import_pattern = r'import\\s+\"([^\"]+)\"'\n        relationships['imports'] = re.findall(import_pattern, content)\n        \n        return relationships\n    \n    def _extract_test_relationships(self, content: str) -> Dict[str, List[str]]:\n        \"\"\"Extract test relationships (what functions/modules are being tested)\"\"\"\n        relationships = {\n            'tests': [],\n            'validates': []\n        }\n        \n        # This would be more sophisticated in practice\n        # Extract function calls in test code to infer what's being tested\n        \n        return relationships\n    \n    def _map_controls_to_artifacts(self) -> Dict[str, List[str]]:\n        \"\"\"Map compliance controls to implementing artifacts\"\"\"\n        control_map = {}\n        \n        for artifact_id, artifact in self.artifacts.items():\n            mapping = artifact.get('compliance_mapping', {})\n            \n            for control in mapping.get('soc2_controls', []):\n                if control not in control_map:\n                    control_map[control] = []\n                control_map[control].append(artifact_id)\n                \n            for control in mapping.get('iso27001_controls', []):\n                if control not in control_map:\n                    control_map[control] = []\n                control_map[control].append(artifact_id)\n        \n        return control_map\n\n# Usage example and CLI interface\nif __name__ == '__main__':\n    import argparse\n    \n    parser = argparse.ArgumentParser(description='Generate HELIX traceability matrix')\n    parser.add_argument('--helix-root', default='docs/helix', help='HELIX documentation root')\n    parser.add_argument('--output', default='traceability-matrix.json', help='Output file')\n    parser.add_argument('--format', choices=['json', 'html', 'csv'], default='json', help='Output format')\n    parser.add_argument('--analyze-gaps', action='store_true', help='Perform gap analysis')\n    parser.add_argument('--validate', action='store_true', help='Validate existing relationships')\n    \n    args = parser.parse_args()\n    \n    # Generate traceability matrix\n    matrix = TraceabilityMatrix(args.helix_root)\n    \n    print(\"ðŸ” Discovering artifacts...\")\n    artifacts = matrix.discover_artifacts()\n    print(f\"Found {len(artifacts)} artifacts\")\n    \n    print(\"ðŸ”— Analyzing dependencies...\")\n    relationships = matrix.analyze_dependencies()\n    print(f\"Found {len(relationships)} relationships\")\n    \n    print(\"ðŸ“Š Generating traceability matrix...\")\n    traceability_data = matrix.generate_traceability_matrix()\n    \n    # Output results\n    if args.format == 'json':\n        with open(args.output, 'w') as f:\n            json.dump(traceability_data, f, indent=2, default=str)\n        print(f\"âœ… Traceability matrix saved to {args.output}\")\n    \n    # Print summary\n    print(\"\\nðŸ“‹ Traceability Summary:\")\n    print(f\"  Total Artifacts: {traceability_data['metadata']['total_artifacts']}\")\n    print(f\"  Total Relationships: {traceability_data['metadata']['total_relationships']}\")\n    print(f\"  Coverage: {traceability_data['metadata']['coverage_analysis']['coverage_percentage']:.1f}%\")\n    \n    gaps = traceability_data['gaps']\n    if gaps:\n        print(f\"\\nâš ï¸ Found {len(gaps)} traceability gaps:\")\n        for gap in gaps[:5]:  # Show first 5 gaps\n            print(f\"  - {gap['type']}: {gap['description']}\")\n        if len(gaps) > 5:\n            print(f\"  ... and {len(gaps) - 5} more\")\n    \n    recommendations = traceability_data['recommendations']\n    if recommendations:\n        print(f\"\\nðŸ’¡ Recommendations:\")\n        for rec in recommendations:\n            print(f\"  - {rec}\")\n```\n\n### Traceability Automation Scripts\n\n#### Continuous Traceability Monitoring\n```bash\n#!/bin/bash\n# scripts/monitor_traceability.sh - Continuous traceability monitoring\n\nset -e\n\nTRACEABILITY_THRESHOLD=80\nGAP_THRESHOLD=5\nREPORT_DIR=\"traceability-reports\"\n\necho \"ðŸ” HELIX Traceability Monitoring\"\necho \"================================\"\n\n# Create reports directory\nmkdir -p \"$REPORT_DIR\"\n\n# Generate current traceability matrix\necho \"ðŸ“Š Generating traceability matrix...\"\npython3 scripts/generate_traceability_matrix.py \\\n    --output \"$REPORT_DIR/current-traceability.json\" \\\n    --analyze-gaps\n\n# Extract key metrics\nCURRENT_COVERAGE=$(jq -r '.metadata.coverage_analysis.coverage_percentage' \"$REPORT_DIR/current-traceability.json\")\nGAP_COUNT=$(jq '.gaps | length' \"$REPORT_DIR/current-traceability.json\")\nORPHANED_ARTIFACTS=$(jq '[.gaps[] | select(.type == \"orphaned_artifact\")] | length' \"$REPORT_DIR/current-traceability.json\")\nMISSING_FORWARD=$(jq '[.gaps[] | select(.type == \"missing_forward_traceability\")] | length' \"$REPORT_DIR/current-traceability.json\")\n\necho \"ðŸ“‹ Current Metrics:\"\necho \"  Coverage: ${CURRENT_COVERAGE}%\"\necho \"  Total Gaps: $GAP_COUNT\"\necho \"  Orphaned Artifacts: $ORPHANED_ARTIFACTS\"\necho \"  Missing Forward Traces: $MISSING_FORWARD\"\n\n# Check thresholds\nCOVERAGE_OK=false\nif (( $(echo \"$CURRENT_COVERAGE >= $TRACEABILITY_THRESHOLD\" | bc -l) )); then\n    COVERAGE_OK=true\nfi\n\nGAPS_OK=false\nif [[ $GAP_COUNT -le $GAP_THRESHOLD ]]; then\n    GAPS_OK=true\nfi\n\n# Generate alerts if needed\nif [[ \"$COVERAGE_OK\" == \"false\" ]] || [[ \"$GAPS_OK\" == \"false\" ]]; then\n    echo \"âš ï¸ Traceability issues detected!\"\n    \n    # Create alert report\n    cat > \"$REPORT_DIR/traceability-alert.md\" << EOF\n# Traceability Alert Report\n\n**Generated**: $(date)\n**Coverage**: ${CURRENT_COVERAGE}% (Threshold: ${TRACEABILITY_THRESHOLD}%)\n**Gaps**: $GAP_COUNT (Threshold: â‰¤ $GAP_THRESHOLD)\n\n## Issues Detected\n\nEOF\n    \n    if [[ \"$COVERAGE_OK\" == \"false\" ]]; then\n        echo \"- âŒ **Coverage Below Threshold**: ${CURRENT_COVERAGE}% < ${TRACEABILITY_THRESHOLD}%\" >> \"$REPORT_DIR/traceability-alert.md\"\n    fi\n    \n    if [[ \"$GAPS_OK\" == \"false\" ]]; then\n        echo \"- âŒ **Too Many Gaps**: $GAP_COUNT > $GAP_THRESHOLD\" >> \"$REPORT_DIR/traceability-alert.md\"\n    fi\n    \n    echo \"\" >> \"$REPORT_DIR/traceability-alert.md\"\n    echo \"## Gap Details\" >> \"$REPORT_DIR/traceability-alert.md\"\n    echo \"\" >> \"$REPORT_DIR/traceability-alert.md\"\n    \n    # Add gap details to report\n    jq -r '.gaps[] | \"- **\\(.type)**: \\(.description) (Severity: \\(.severity))\"' \\\n        \"$REPORT_DIR/current-traceability.json\" >> \"$REPORT_DIR/traceability-alert.md\"\n    \n    echo \"\" >> \"$REPORT_DIR/traceability-alert.md\"\n    echo \"## Recommendations\" >> \"$REPORT_DIR/traceability-alert.md\"\n    echo \"\" >> \"$REPORT_DIR/traceability-alert.md\"\n    \n    # Add recommendations\n    jq -r '.recommendations[] | \"- \\(.)\"' \\\n        \"$REPORT_DIR/current-traceability.json\" >> \"$REPORT_DIR/traceability-alert.md\"\n    \n    # Send notification if configured\n    if [[ -n \"$SLACK_WEBHOOK\" ]]; then\n        curl -X POST \"$SLACK_WEBHOOK\" \\\n            -H \"Content-Type: application/json\" \\\n            -d \"{\n                \\\"text\\\": \\\"âš ï¸ HELIX Traceability Issues Detected\\\",\n                \\\"attachments\\\": [{\n                    \\\"color\\\": \\\"warning\\\",\n                    \\\"fields\\\": [\n                        {\\\"title\\\": \\\"Coverage\\\", \\\"value\\\": \\\"${CURRENT_COVERAGE}%\\\", \\\"short\\\": true},\n                        {\\\"title\\\": \\\"Gaps\\\", \\\"value\\\": \\\"$GAP_COUNT\\\", \\\"short\\\": true},\n                        {\\\"title\\\": \\\"Report\\\", \\\"value\\\": \\\"See traceability-alert.md\\\", \\\"short\\\": false}\n                    ]\n                }]\n            }\"\n    fi\n    \n    echo \"ðŸ“‹ Alert report generated: $REPORT_DIR/traceability-alert.md\"\n    exit 1\nelse\n    echo \"âœ… Traceability metrics within acceptable thresholds\"\nfi\n\n# Compare with previous report if available\nif [[ -f \"$REPORT_DIR/previous-traceability.json\" ]]; then\n    echo \"ðŸ“ˆ Comparing with previous report...\"\n    \n    PREVIOUS_COVERAGE=$(jq -r '.metadata.coverage_analysis.coverage_percentage' \"$REPORT_DIR/previous-traceability.json\")\n    PREVIOUS_GAPS=$(jq '.gaps | length' \"$REPORT_DIR/previous-traceability.json\")\n    \n    COVERAGE_CHANGE=$(echo \"$CURRENT_COVERAGE - $PREVIOUS_COVERAGE\" | bc -l)\n    GAP_CHANGE=$(echo \"$GAP_COUNT - $PREVIOUS_GAPS\" | bc)\n    \n    echo \"ðŸ“Š Changes since last report:\"\n    echo \"  Coverage: ${COVERAGE_CHANGE:+${COVERAGE_CHANGE}%} (was ${PREVIOUS_COVERAGE}%)\"\n    echo \"  Gaps: ${GAP_CHANGE:+${GAP_CHANGE}} (was $PREVIOUS_GAPS)\"\n    \n    # Generate trend report\n    cat > \"$REPORT_DIR/traceability-trend.json\" << EOF\n{\n  \"current\": {\n    \"coverage\": $CURRENT_COVERAGE,\n    \"gaps\": $GAP_COUNT,\n    \"timestamp\": \"$(date -Iseconds)\"\n  },\n  \"previous\": {\n    \"coverage\": $PREVIOUS_COVERAGE,\n    \"gaps\": $PREVIOUS_GAPS\n  },\n  \"changes\": {\n    \"coverage_change\": $COVERAGE_CHANGE,\n    \"gap_change\": $GAP_CHANGE,\n    \"trend\": \"$(if (( $(echo \"$COVERAGE_CHANGE > 0\" | bc -l) )) && (( GAP_CHANGE <= 0 )); then echo 'improving'; elif (( $(echo \"$COVERAGE_CHANGE < 0\" | bc -l) )) || (( GAP_CHANGE > 0 )); then echo 'degrading'; else echo 'stable'; fi)\"\n  }\n}\nEOF\nfi\n\n# Archive current report as previous\ncp \"$REPORT_DIR/current-traceability.json\" \"$REPORT_DIR/previous-traceability.json\"\n\n# Generate summary dashboard\ncat > \"$REPORT_DIR/traceability-dashboard.html\" << 'EOF'\n<!DOCTYPE html>\n<html>\n<head>\n    <title>HELIX Traceability Dashboard</title>\n    <style>\n        body { font-family: Arial, sans-serif; margin: 40px; }\n        .metric { display: inline-block; margin: 20px; padding: 20px; border: 1px solid #ddd; border-radius: 5px; }\n        .good { background-color: #d4edda; border-color: #c3e6cb; }\n        .warning { background-color: #fff3cd; border-color: #ffeaa7; }\n        .danger { background-color: #f8d7da; border-color: #f5c6cb; }\n        .metric h3 { margin: 0 0 10px 0; }\n        .metric .value { font-size: 2em; font-weight: bold; }\n    </style>\n</head>\n<body>\n    <h1>HELIX Traceability Dashboard</h1>\n    <p>Generated: $(date)</p>\n    \n    <div class=\"metric $(if [[ \"$COVERAGE_OK\" == \"true\" ]]; then echo 'good'; else echo 'danger'; fi)\">\n        <h3>Coverage</h3>\n        <div class=\"value\">${CURRENT_COVERAGE}%</div>\n        <div>Threshold: ${TRACEABILITY_THRESHOLD}%</div>\n    </div>\n    \n    <div class=\"metric $(if [[ \"$GAPS_OK\" == \"true\" ]]; then echo 'good'; else echo 'warning'; fi)\">\n        <h3>Gaps</h3>\n        <div class=\"value\">$GAP_COUNT</div>\n        <div>Threshold: â‰¤ $GAP_THRESHOLD</div>\n    </div>\n    \n    <div class=\"metric\">\n        <h3>Orphaned Artifacts</h3>\n        <div class=\"value\">$ORPHANED_ARTIFACTS</div>\n    </div>\n    \n    <div class=\"metric\">\n        <h3>Missing Forward Traces</h3>\n        <div class=\"value\">$MISSING_FORWARD</div>\n    </div>\n    \n    <h2>Recent Reports</h2>\n    <ul>\n        <li><a href=\"current-traceability.json\">Current Traceability Matrix</a></li>\n        <li><a href=\"traceability-alert.md\">Alert Report</a> (if available)</li>\n        <li><a href=\"traceability-trend.json\">Trend Analysis</a> (if available)</li>\n    </ul>\n</body>\n</html>\nEOF\n\necho \"ðŸ“Š Dashboard generated: $REPORT_DIR/traceability-dashboard.html\"\necho \"âœ… Traceability monitoring completed\"\n```\n\n### Change Impact Analysis\n\n#### Automated Impact Assessment\n```python\n#!/usr/bin/env python3\n# scripts/analyze_change_impact.py\n\nimport json\nimport sys\nimport subprocess\nfrom pathlib import Path\nfrom typing import Dict, List, Set\nfrom dataclasses import dataclass\n\n@dataclass\nclass ChangeImpact:\n    changed_artifact: str\n    impacted_artifacts: List[str]\n    impact_type: str  # \"direct\", \"indirect\", \"compliance\"\n    severity: str     # \"low\", \"medium\", \"high\", \"critical\"\n    required_actions: List[str]\n\nclass ChangeImpactAnalyzer:\n    def __init__(self, traceability_file: str = \"traceability-matrix.json\"):\n        with open(traceability_file, 'r') as f:\n            self.traceability_data = json.load(f)\n        \n        self.artifacts = self.traceability_data['artifacts']\n        self.relationships = self.traceability_data['relationships']\n        \n        # Build relationship maps for efficient lookup\n        self.forward_deps = {}  # artifact -> [artifacts that depend on it]\n        self.reverse_deps = {}  # artifact -> [artifacts it depends on]\n        \n        for rel in self.relationships:\n            source, target = rel['source'], rel['target']\n            \n            if target not in self.forward_deps:\n                self.forward_deps[target] = []\n            self.forward_deps[target].append(source)\n            \n            if source not in self.reverse_deps:\n                self.reverse_deps[source] = []\n            self.reverse_deps[source].append(target)\n    \n    def analyze_git_changes(self, commit_range: str = \"HEAD~1..HEAD\") -> List[ChangeImpact]:\n        \"\"\"Analyze impact of changes in git commit range\"\"\"\n        # Get changed files\n        result = subprocess.run(\n            ['git', 'diff', '--name-only', commit_range],\n            capture_output=True, text=True\n        )\n        \n        if result.returncode != 0:\n            print(f\"Error getting git changes: {result.stderr}\")\n            return []\n        \n        changed_files = result.stdout.strip().split('\\n')\n        if not changed_files or changed_files == ['']:\n            print(\"No changes detected\")\n            return []\n        \n        print(f\"Analyzing impact of changes to {len(changed_files)} files:\")\n        for file in changed_files:\n            print(f\"  - {file}\")\n        \n        # Map changed files to artifacts\n        changed_artifacts = self._map_files_to_artifacts(changed_files)\n        \n        # Analyze impact for each changed artifact\n        all_impacts = []\n        for artifact_id in changed_artifacts:\n            impacts = self._analyze_artifact_impact(artifact_id)\n            all_impacts.extend(impacts)\n        \n        return all_impacts\n    \n    def _map_files_to_artifacts(self, changed_files: List[str]) -> List[str]:\n        \"\"\"Map changed files to artifact IDs\"\"\"\n        changed_artifacts = []\n        \n        for file_path in changed_files:\n            for artifact_id, artifact in self.artifacts.items():\n                artifact_file = artifact.get('metadata', {}).get('file_path', '')\n                if artifact_file and Path(artifact_file).resolve() == Path(file_path).resolve():\n                    changed_artifacts.append(artifact_id)\n                    break\n        \n        return changed_artifacts\n    \n    def _analyze_artifact_impact(self, artifact_id: str) -> List[ChangeImpact]:\n        \"\"\"Analyze impact of changes to a specific artifact\"\"\"\n        impacts = []\n        \n        if artifact_id not in self.artifacts:\n            return impacts\n        \n        artifact = self.artifacts[artifact_id]\n        \n        # Direct impacts (artifacts that directly depend on this one)\n        direct_dependents = self.forward_deps.get(artifact_id, [])\n        if direct_dependents:\n            impacts.append(ChangeImpact(\n                changed_artifact=artifact_id,\n                impacted_artifacts=direct_dependents,\n                impact_type=\"direct\",\n                severity=self._calculate_severity(artifact, direct_dependents),\n                required_actions=self._suggest_actions(\"direct\", artifact, direct_dependents)\n            ))\n        \n        # Indirect impacts (transitively dependent artifacts)\n        indirect_dependents = self._find_transitive_dependents(artifact_id, direct_dependents)\n        if indirect_dependents:\n            impacts.append(ChangeImpact(\n                changed_artifact=artifact_id,\n                impacted_artifacts=indirect_dependents,\n                impact_type=\"indirect\",\n                severity=self._calculate_severity(artifact, indirect_dependents),\n                required_actions=self._suggest_actions(\"indirect\", artifact, indirect_dependents)\n            ))\n        \n        # Compliance impacts\n        compliance_impacts = self._analyze_compliance_impact(artifact_id)\n        if compliance_impacts:\n            impacts.append(compliance_impacts)\n        \n        return impacts\n    \n    def _find_transitive_dependents(self, artifact_id: str, direct_deps: List[str]) -> List[str]:\n        \"\"\"Find artifacts that transitively depend on the changed artifact\"\"\"\n        visited = set(direct_deps + [artifact_id])\n        queue = direct_deps.copy()\n        transitive = []\n        \n        while queue:\n            current = queue.pop(0)\n            dependents = self.forward_deps.get(current, [])\n            \n            for dep in dependents:\n                if dep not in visited:\n                    visited.add(dep)\n                    queue.append(dep)\n                    transitive.append(dep)\n        \n        return transitive\n    \n    def _analyze_compliance_impact(self, artifact_id: str) -> ChangeImpact:\n        \"\"\"Analyze compliance-related impacts\"\"\"\n        artifact = self.artifacts[artifact_id]\n        compliance_mapping = artifact.get('compliance_mapping', {})\n        \n        # Check if artifact affects compliance controls\n        affected_controls = []\n        affected_controls.extend(compliance_mapping.get('soc2_controls', []))\n        affected_controls.extend(compliance_mapping.get('iso27001_controls', []))\n        affected_controls.extend(compliance_mapping.get('evidence_tasks', []))\n        \n        if not affected_controls:\n            return None\n        \n        # Find other artifacts that implement the same controls\n        related_artifacts = []\n        for other_id, other_artifact in self.artifacts.items():\n            if other_id == artifact_id:\n                continue\n                \n            other_mapping = other_artifact.get('compliance_mapping', {})\n            other_controls = []\n            other_controls.extend(other_mapping.get('soc2_controls', []))\n            other_controls.extend(other_mapping.get('iso27001_controls', []))\n            other_controls.extend(other_mapping.get('evidence_tasks', []))\n            \n            if any(control in affected_controls for control in other_controls):\n                related_artifacts.append(other_id)\n        \n        return ChangeImpact(\n            changed_artifact=artifact_id,\n            impacted_artifacts=related_artifacts,\n            impact_type=\"compliance\",\n            severity=\"high\" if affected_controls else \"low\",\n            required_actions=[\n                f\"Review compliance controls: {', '.join(affected_controls[:5])}\",\n                \"Update compliance documentation\",\n                \"Verify evidence collection still works\",\n                \"Run compliance validation tests\"\n            ]\n        )\n    \n    def _calculate_severity(self, artifact: Dict, impacted: List[str]) -> str:\n        \"\"\"Calculate impact severity based on artifact type and number of impacts\"\"\"\n        phase = artifact['metadata']['phase']\n        category = artifact['metadata']['category']\n        impact_count = len(impacted)\n        \n        # High severity for requirements and architecture changes\n        if category in ['requirements', 'architecture'] and impact_count > 0:\n            return \"high\"\n        \n        # Medium severity for design and security changes\n        if category in ['security', 'design'] and impact_count > 2:\n            return \"medium\"\n        \n        # Critical severity for frame phase changes with many impacts\n        if phase == 'frame' and impact_count > 5:\n            return \"critical\"\n        \n        # Default based on impact count\n        if impact_count > 10:\n            return \"high\"\n        elif impact_count > 5:\n            return \"medium\"\n        else:\n            return \"low\"\n    \n    def _suggest_actions(self, impact_type: str, artifact: Dict, impacted: List[str]) -> List[str]:\n        \"\"\"Suggest required actions based on impact type\"\"\"\n        actions = []\n        phase = artifact['metadata']['phase']\n        \n        if impact_type == \"direct\":\n            actions.extend([\n                f\"Review {len(impacted)} directly impacted artifacts\",\n                \"Update dependent documentation\",\n                \"Run affected tests\"\n            ])\n            \n            if phase == 'frame':\n                actions.append(\"Re-validate requirements with stakeholders\")\n            elif phase == 'design':\n                actions.append(\"Update architecture documentation\")\n            elif phase == 'test':\n                actions.append(\"Re-run test suite\")\n        \n        elif impact_type == \"indirect\":\n            actions.extend([\n                f\"Assess {len(impacted)} transitively impacted artifacts\",\n                \"Consider broader system implications\",\n                \"Update integration tests\"\n            ])\n        \n        return actions\n    \n    def generate_impact_report(self, impacts: List[ChangeImpact]) -> Dict:\n        \"\"\"Generate comprehensive impact report\"\"\"\n        if not impacts:\n            return {\n                \"summary\": \"No impacts detected\",\n                \"total_impacts\": 0,\n                \"severity_breakdown\": {},\n                \"recommendations\": []\n            }\n        \n        # Calculate severity breakdown\n        severity_counts = {}\n        for impact in impacts:\n            severity = impact.severity\n            severity_counts[severity] = severity_counts.get(severity, 0) + 1\n        \n        # Get unique impacted artifacts\n        all_impacted = set()\n        for impact in impacts:\n            all_impacted.update(impact.impacted_artifacts)\n        \n        # Generate recommendations\n        recommendations = []\n        if any(impact.severity in ['critical', 'high'] for impact in impacts):\n            recommendations.append(\"Immediate review required for high-severity impacts\")\n        \n        if any(impact.impact_type == 'compliance' for impact in impacts):\n            recommendations.append(\"Compliance validation required\")\n        \n        if len(all_impacted) > 10:\n            recommendations.append(\"Consider phased implementation due to broad impact\")\n        \n        return {\n            \"summary\": f\"Change impacts {len(all_impacted)} artifacts across {len(impacts)} categories\",\n            \"total_impacts\": len(all_impacted),\n            \"impact_categories\": len(impacts),\n            \"severity_breakdown\": severity_counts,\n            \"impacts\": [\n                {\n                    \"changed_artifact\": impact.changed_artifact,\n                    \"impact_type\": impact.impact_type,\n                    \"severity\": impact.severity,\n                    \"impacted_count\": len(impact.impacted_artifacts),\n                    \"impacted_artifacts\": impact.impacted_artifacts,\n                    \"required_actions\": impact.required_actions\n                }\n                for impact in impacts\n            ],\n            \"recommendations\": recommendations,\n            \"generated_at\": subprocess.check_output(['date', '-Iseconds']).decode().strip()\n        }\n\nif __name__ == '__main__':\n    import argparse\n    \n    parser = argparse.ArgumentParser(description='Analyze change impact across HELIX artifacts')\n    parser.add_argument('--traceability-file', default='traceability-matrix.json',\n                       help='Traceability matrix file')\n    parser.add_argument('--commit-range', default='HEAD~1..HEAD',\n                       help='Git commit range to analyze')\n    parser.add_argument('--output', default='change-impact-report.json',\n                       help='Output report file')\n    parser.add_argument('--format', choices=['json', 'markdown'], default='json',\n                       help='Output format')\n    \n    args = parser.parse_args()\n    \n    # Check if traceability file exists\n    if not Path(args.traceability_file).exists():\n        print(f\"âŒ Traceability file not found: {args.traceability_file}\")\n        print(\"Run generate_traceability_matrix.py first\")\n        sys.exit(1)\n    \n    analyzer = ChangeImpactAnalyzer(args.traceability_file)\n    \n    print(f\"ðŸ” Analyzing change impact for commit range: {args.commit_range}\")\n    impacts = analyzer.analyze_git_changes(args.commit_range)\n    \n    if not impacts:\n        print(\"âœ… No impacts detected\")\n        sys.exit(0)\n    \n    report = analyzer.generate_impact_report(impacts)\n    \n    # Save report\n    with open(args.output, 'w') as f:\n        json.dump(report, f, indent=2)\n    \n    # Print summary\n    print(f\"\\nðŸ“Š Change Impact Summary:\")\n    print(f\"  {report['summary']}\")\n    print(f\"  Severity breakdown: {report['severity_breakdown']}\")\n    \n    if report['recommendations']:\n        print(f\"\\nðŸ’¡ Recommendations:\")\n        for rec in report['recommendations']:\n            print(f\"  - {rec}\")\n    \n    print(f\"\\nðŸ“‹ Full report saved to: {args.output}\")\n    \n    # Exit with error code if high-severity impacts detected\n    if any(impact['severity'] in ['critical', 'high'] for impact in report['impacts']):\n        print(\"âš ï¸ High-severity impacts detected - review required\")\n        sys.exit(1)\n```\n\n### Integration with CI/CD Pipeline\n\n#### Pre-commit Traceability Check\n```bash\n#!/bin/bash\n# .githooks/pre-commit-traceability-check\n\nset -e\n\necho \"ðŸ” Checking traceability before commit...\"\n\n# Generate current traceability matrix\npython3 scripts/generate_traceability_matrix.py \\\n    --output \".temp-traceability.json\" \\\n    --analyze-gaps\n\n# Check if we're below thresholds\nCOVERAGE=$(jq -r '.metadata.coverage_analysis.coverage_percentage' \".temp-traceability.json\")\nGAP_COUNT=$(jq '.gaps | length' \".temp-traceability.json\")\n\nMIN_COVERAGE=75\nMAX_GAPS=10\n\nif (( $(echo \"$COVERAGE < $MIN_COVERAGE\" | bc -l) )); then\n    echo \"âŒ Traceability coverage too low: ${COVERAGE}% < ${MIN_COVERAGE}%\"\n    echo \"   Add artifact relationships before committing\"\n    rm \".temp-traceability.json\"\n    exit 1\nfi\n\nif [[ $GAP_COUNT -gt $MAX_GAPS ]]; then\n    echo \"âŒ Too many traceability gaps: $GAP_COUNT > $MAX_GAPS\"\n    echo \"   Fix traceability gaps before committing\"\n    rm \".temp-traceability.json\"\n    exit 1\nfi\n\necho \"âœ… Traceability checks passed\"\nrm \".temp-traceability.json\"\n```\n\n#### GitHub Actions Workflow\n```yaml\n# .github/workflows/traceability-check.yml\nname: Traceability Analysis\n\non:\n  push:\n    branches: [ main, develop ]\n  pull_request:\n    branches: [ main ]\n\njobs:\n  traceability:\n    runs-on: ubuntu-latest\n    \n    steps:\n    - uses: actions/checkout@v3\n      with:\n        fetch-depth: 0  # Need full history for change analysis\n    \n    - name: Set up Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: '3.9'\n    \n    - name: Install dependencies\n      run: |\n        pip install -r requirements.txt\n    \n    - name: Generate traceability matrix\n      run: |\n        python3 scripts/generate_traceability_matrix.py \\\n          --output traceability-matrix.json \\\n          --analyze-gaps\n    \n    - name: Analyze change impact\n      if: github.event_name == 'pull_request'\n      run: |\n        python3 scripts/analyze_change_impact.py \\\n          --commit-range origin/main..HEAD \\\n          --output change-impact-report.json\n    \n    - name: Check traceability thresholds\n      run: |\n        COVERAGE=$(jq -r '.metadata.coverage_analysis.coverage_percentage' traceability-matrix.json)\n        GAP_COUNT=$(jq '.gaps | length' traceability-matrix.json)\n        \n        echo \"Coverage: ${COVERAGE}%\"\n        echo \"Gaps: $GAP_COUNT\"\n        \n        if (( $(echo \"$COVERAGE < 80\" | bc -l) )); then\n          echo \"âŒ Coverage below 80%: ${COVERAGE}%\"\n          exit 1\n        fi\n        \n        if [[ $GAP_COUNT -gt 5 ]]; then\n          echo \"âŒ Too many gaps: $GAP_COUNT\"\n          exit 1\n        fi\n        \n        echo \"âœ… Traceability checks passed\"\n    \n    - name: Upload traceability artifacts\n      uses: actions/upload-artifact@v3\n      with:\n        name: traceability-reports\n        path: |\n          traceability-matrix.json\n          change-impact-report.json\n          traceability-reports/\n    \n    - name: Comment on PR\n      if: github.event_name == 'pull_request' && always()\n      uses: actions/github-script@v6\n      with:\n        script: |\n          const fs = require('fs');\n          \n          let comment = '## ðŸ”— Traceability Analysis\\n\\n';\n          \n          try {\n            const matrix = JSON.parse(fs.readFileSync('traceability-matrix.json', 'utf8'));\n            const coverage = matrix.metadata.coverage_analysis.coverage_percentage;\n            const gaps = matrix.gaps.length;\n            \n            comment += `**Coverage**: ${coverage.toFixed(1)}%\\n`;\n            comment += `**Gaps**: ${gaps}\\n\\n`;\n            \n            if (fs.existsSync('change-impact-report.json')) {\n              const impact = JSON.parse(fs.readFileSync('change-impact-report.json', 'utf8'));\n              comment += `**Change Impact**: ${impact.summary}\\n`;\n              \n              if (impact.recommendations.length > 0) {\n                comment += '\\n**Recommendations**:\\n';\n                impact.recommendations.forEach(rec => {\n                  comment += `- ${rec}\\n`;\n                });\n              }\n            }\n          } catch (error) {\n            comment += `Error reading traceability reports: ${error.message}`;\n          }\n          \n          github.rest.issues.createComment({\n            issue_number: context.issue.number,\n            owner: context.repo.owner,\n            repo: context.repo.repo,\n            body: comment\n          });\n```\n\n---\n\n*This comprehensive cross-phase dependency traceability system ensures complete visibility and control over the relationships between all HELIX artifacts, enabling effective change management, impact analysis, and compliance validation throughout the development lifecycle.*